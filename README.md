# textflow
![Technological Stack](images/Stack_Logos.png)
Training pipelines in Natural Language Processing with [TensorFlow](https://www.tensorflow.org/), [Metaflow](https://metaflow.org/) and [Amazon Web Services](https://aws.amazon.com/fr/).

## Models
Word/Sentence Representation :
  * [ ] [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/pdf/1310.4546.pdf)
  * [ ] [Supervised Learning of Universal Sentence Representations from Natural Language Inference Data](https://arxiv.org/pdf/1705.02364.pdf)
  * [ ] [A Structured Self-Attentive Sentence Embedding](https://arxiv.org/pdf/1703.03130.pdf)
  
Text classification :
  * [ ] [Hierarchical Attention Networks for Document Classification](https://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf)
  * [ ] [Quasi-Recurrent Neural Networks](https://arxiv.org/pdf/1611.01576.pdf)


Neural Machine Translation :
  * [ ] [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/pdf/1409.0473.pdf)
  * [ ] [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/pdf/1508.04025.pdf)
  * [ ] [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
  * [ ] [Pay Less Attention with Lightweight and Dynamic Convolutions](https://arxiv.org/pdf/1901.10430.pdf)


## License
This project is under the MIT License.